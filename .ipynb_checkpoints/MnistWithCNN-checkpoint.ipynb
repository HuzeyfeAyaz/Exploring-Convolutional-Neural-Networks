{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZLcv1LnqcRR"
   },
   "source": [
    "# Evaluating Mnist Dataset With Convolutional Neural Networks\n",
    "\n",
    "As you remember, we had evaluated the MNIST dataset before using only densely connected layers. Thanks to Artificial Convolutional Networks (ConvNets), we can catch some patters using filters from images like edges of the objects, color differences, or shapes. In this notebook, we are going to explore convolutional neural networks and use them to obtain a better result.\n",
    "\n",
    "The convolutional architecture of the used model at the end of this dataset looks like below;\n",
    "\n",
    "<img src=\"images/ConvolutionalArchitecture.png\">\n",
    "\n",
    "Each convolutional filter has the shape of a 3x3 kernel while pooling filters have a 2x2. For the convolutional and pooling layers, we are applying element-wise multiplication in sliding windows manner.\n",
    "\n",
    "For the example of Vertical edge detection below (padding=0, stride=1);\n",
    "\n",
    "<img src=\"images/Filters.png\">\n",
    "\n",
    "Max pooling takes the maximum value in each window. It is generally used with a 2x2 kernel, and stride 2. For this reason, the output dimensions of a max-pooling layer would be half of the input.\n",
    "\n",
    "For the example of max pooling;\n",
    "\n",
    "<img src=\"images/MaxPooling.png\" width=600 height=480>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_Yllqcyvlru"
   },
   "source": [
    "### Importing Required Modules and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQOTO-FJV8yW"
   },
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2126,
     "status": "ok",
     "timestamp": 1594731514354,
     "user": {
      "displayName": "Huzeyfe Ayaz",
      "photoUrl": "",
      "userId": "04212809444872264866"
     },
     "user_tz": -180
    },
    "id": "mrdHCXC1ZSyE",
    "outputId": "9b7241e6-9bfa-4e4d-fe55-e61e03fe1d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_edwMIDv4m4"
   },
   "source": [
    "* Because convolutional layers accept 4D tensors, we should reshape the data to the following format; (sample, height, weight, channel).\n",
    "\n",
    "* Pixels are divided by 255 for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ElPBzSAZ8EV"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8udTN0kFw_pO"
   },
   "source": [
    "### Creating and  Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgaOMRkjXgMq"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1594731098678,
     "user": {
      "displayName": "Huzeyfe Ayaz",
      "photoUrl": "",
      "userId": "04212809444872264866"
     },
     "user_tz": -180
    },
    "id": "NcFlUV3BYUYz",
    "outputId": "98068678-4fd6-4adb-a1b6-5aea7b6f98b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "du1buYiGqqaL"
   },
   "source": [
    "In the convolutional part of the model, we have used 3 convolutional layers and 2 max-pooling layers.\n",
    "\n",
    "* Generally, convolutional layers are used with 3-by-3 filters while pooling layers are 2-by-2. That allows us to minimize input parameters for densely connected layers in terms of computational efficiency. In this example, we had 28x28x1 = 784 parameters at the beginning of the model. But at the end of the convolutional part, it has been shaped to 3x3x64 = 576. Moreover, imagine that we have RGB images with 3 channels. In this case, we would have 28x28x3 = 2352 parameters, which are 3 times more than our initial point.\n",
    "\n",
    "* We can calculate the output of the convolutional layer with the formula of `[(n + 2p - f)/s] + 1` which `n` represents the length of the input while `p` for paddings and `f` for filter size. Then, divide them by stride and add 1 to the total result.\n",
    "\n",
    "* Max-pooling reduces input size half since we used filter size as 2, and that takes strides automatically as 2.\n",
    "\n",
    "* For this reason, the filter number in the convolutional layer is increasing gradually to catch more patterns while the output shape is decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ciSl2f96YWho"
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1594731344494,
     "user": {
      "displayName": "Huzeyfe Ayaz",
      "photoUrl": "",
      "userId": "04212809444872264866"
     },
     "user_tz": -180
    },
    "id": "G1795bntZOiS",
    "outputId": "9e0039d4-92a9-4c8a-d3a1-42b860a4cc8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wihTDn1JvHQk"
   },
   "source": [
    "* After convolutional layers, we should flat the parameters for densely connected layers.\n",
    "\n",
    "* In the end, we have 93,322 trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29578,
     "status": "ok",
     "timestamp": 1594731710435,
     "user": {
      "displayName": "Huzeyfe Ayaz",
      "photoUrl": "",
      "userId": "04212809444872264866"
     },
     "user_tz": -180
    },
    "id": "LuzrPCt9aU3O",
    "outputId": "b6907f40-5556-4017-afaa-5eafca44918f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.1649 - accuracy: 0.9473\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0461 - accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0321 - accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0244 - accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0194 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe5e01510f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1667,
     "status": "ok",
     "timestamp": 1594731722356,
     "user": {
      "displayName": "Huzeyfe Ayaz",
      "photoUrl": "",
      "userId": "04212809444872264866"
     },
     "user_tz": -180
    },
    "id": "zknWlXwOalQB",
    "outputId": "3e07d4d2-ca76-4973-959a-e2c924d38901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9927999973297119"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "On2u94n_zMze"
   },
   "source": [
    "As a result, thanks to convolutional layers, we have achieved 99% accuracy within only 5 epochs for the MNIST dataset."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNRjYsMYzmiw0+Bx47xiNps",
   "collapsed_sections": [],
   "name": "5.1.MnistWithCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
